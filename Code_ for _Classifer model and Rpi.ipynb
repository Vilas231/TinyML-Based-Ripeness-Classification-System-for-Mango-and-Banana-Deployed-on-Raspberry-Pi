{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4V7C861JRlGe"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Replace with your actual filename if different\n",
        "zip_path = \"/content/Mango_Banana_Dataset.zip\"\n",
        "extract_path = \"/content/data\"\n",
        "\n",
        "# Unzip the dataset\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Verify extraction\n",
        "print(\"Top-level contents after extraction:\")\n",
        "print(os.listdir(extract_path))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This script trains a mango classifier (Raw, Ripe, Not a Mango) with data augmentation, fine-tuning,\n",
        "# and saves the model as TFLite. It also evaluates the test accuracy.\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "# --- Parameters ---\n",
        "TRAIN_PATH = \"/content/data/data/train/images\"\n",
        "TEST_PATH = \"/content/data/data/test/images\"\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "CLASS_NAMES = [\"Raw_Mango\", \"Ripe_Mango\", \"Not_a_Mango\"]\n",
        "\n",
        "# --- Labeling from filename ---\n",
        "def label_from_filename(filename):\n",
        "    fname = filename.lower()\n",
        "    if \"raw_mango\" in fname:\n",
        "        return 0\n",
        "    elif \"ripe_mango\" in fname:\n",
        "        return 1\n",
        "    elif \"ripe_banana\" in fname or \"raw_banana\" in fname:\n",
        "        return 2\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# --- Load and label training data ---\n",
        "image_paths = [os.path.join(TRAIN_PATH, fname) for fname in os.listdir(TRAIN_PATH) if fname.endswith(('.jpg', '.png'))]\n",
        "labeled_paths = [(p, label_from_filename(p)) for p in image_paths if label_from_filename(p) is not None]\n",
        "\n",
        "# --- Balance classes ---\n",
        "class_paths = {0: [], 1: [], 2: []}\n",
        "for path, label in labeled_paths:\n",
        "    class_paths[label].append(path)\n",
        "\n",
        "min_count = min(len(paths) for paths in class_paths.values())\n",
        "balanced_paths = []\n",
        "for label in class_paths:\n",
        "    selected = random.sample(class_paths[label], min_count)\n",
        "    balanced_paths.extend([(p, label) for p in selected])\n",
        "\n",
        "random.shuffle(balanced_paths)\n",
        "print(f\"âœ… Balanced dataset to {min_count} samples per class\")\n",
        "print(f\"âœ… Total training samples: {len(balanced_paths)}\")\n",
        "\n",
        "# --- Load and preprocess training images ---\n",
        "def preprocess_image(path):\n",
        "    img = load_img(path, target_size=IMG_SIZE)\n",
        "    img = img_to_array(img) / 255.0\n",
        "    return img\n",
        "\n",
        "X_train = np.array([preprocess_image(p) for p, _ in balanced_paths])\n",
        "y_train = np.array([label for _, label in balanced_paths])\n",
        "\n",
        "# --- Data augmentation ---\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# --- Build model ---\n",
        "base_model = MobileNetV2(include_top=False, input_shape=(224, 224, 3), weights=\"imagenet\")\n",
        "base_model.trainable = True\n",
        "\n",
        "# Unfreeze only top 50 layers\n",
        "for layer in base_model.layers[:-50]:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(len(CLASS_NAMES), activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# --- Train model ---\n",
        "print(\"ðŸš€ Training mango classifier (no validation set)...\")\n",
        "model.fit(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
        "          epochs=EPOCHS,\n",
        "          steps_per_epoch=len(X_train)//BATCH_SIZE,\n",
        "          verbose=1)\n",
        "\n",
        "# --- Save as TFLite model ---\n",
        "print(\" Converting to TFLite...\")\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"mango_classifier_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"TFLite model saved as: mango_classifier_model.tflite\")\n",
        "\n",
        "# --- Evaluate on training set ---\n",
        "train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "print(f\" Final Training Accuracy: {train_acc * 100:.2f}%\")\n",
        "\n",
        "# --- Load and preprocess test images ---\n",
        "test_paths = [os.path.join(TEST_PATH, fname) for fname in os.listdir(TEST_PATH) if fname.endswith(('.jpg', '.png'))]\n",
        "test_data = [(p, label_from_filename(p)) for p in test_paths if label_from_filename(p) is not None]\n",
        "\n",
        "X_test = np.array([preprocess_image(p) for p, _ in test_data])\n",
        "y_test = np.array([label for _, label in test_data])\n",
        "\n",
        "# --- Evaluate on test set ---\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\" Final Test Accuracy: {test_acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "Gp3sUG6dR4lZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This script loads your mango_classifier_model.tflite and classifies all unique images, showing predictions visually and printing confidence.\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Load the TFLite model ---\n",
        "interpreter = tf.lite.Interpreter(model_path=\"mango_classifier_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# --- Get input/output details ---\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# --- Class names used during training ---\n",
        "class_names = [\"Raw_Mango\", \"Ripe_Mango\", \"Not_a_Mango\"]\n",
        "\n",
        "# --- Preprocessing function ---\n",
        "def preprocess_image(img_path):\n",
        "    img = Image.open(img_path).resize((224, 224)).convert(\"RGB\")\n",
        "    img_arr = np.array(img) / 255.0\n",
        "    img_arr = img_arr.astype(np.float32)\n",
        "    img_arr = np.expand_dims(img_arr, axis=0)\n",
        "    return img, img_arr\n",
        "\n",
        "# --- Prediction and image display ---\n",
        "def classify_and_show(img_path):\n",
        "    try:\n",
        "        img, img_tensor = preprocess_image(img_path)\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], img_tensor)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
        "\n",
        "        pred_idx = np.argmax(output)\n",
        "        pred_label = class_names[pred_idx]\n",
        "        confidence = output[pred_idx]\n",
        "\n",
        "        #  Show image with prediction\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"{pred_label} ({confidence:.2f})\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        # Console output\n",
        "        print(f\" {img_path}\")\n",
        "        print(f\"âž¡ Prediction: {pred_label} (Confidence: {confidence:.2f})\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error with image {img_path}: {e}\")\n",
        "\n",
        "# --- All image paths (deduplicated) ---\n",
        "test_images = list(set([\n",
        "    \"/content/ripebanana1.jpg\",\n",
        "    \"/content/raw_mango.jpg\",\n",
        "    \"/content/raw-mango2.webp\",\n",
        "    \"/content/bunch_mango.jpg\",\n",
        "    \"/content/bunch_banana.jpg\",\n",
        "    \"/content/RW_MG5.jpg\",\n",
        "    \"/content/RP_MG2.jpg\",\n",
        "    \"/content/ripemango.jpg\"\n",
        "]))\n",
        "\n",
        "# --- Run predictions on all test images ---\n",
        "for path in test_images:\n",
        "    classify_and_show(path)"
      ],
      "metadata": {
        "id": "Rn6ZGwRzSIoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BANANA CLASSIFER WITH ACURACY\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dataset source\n",
        "image_dir = '/content/data/data/train/images'\n",
        "output_dir = '/content/banana_data'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Clean folder structure\n",
        "for sub in ['Ripe_Banana', 'Raw_Banana']:\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        os.makedirs(f\"{output_dir}/{split}/{sub}\", exist_ok=True)\n",
        "\n",
        "# File separation\n",
        "all_images = os.listdir(image_dir)\n",
        "ripe_banana = [img for img in all_images if img.lower().startswith(\"ripe_banana\")]\n",
        "raw_banana = [img for img in all_images if img.lower().startswith(\"raw_banana\")]\n",
        "\n",
        "# Use equal number of images for balance\n",
        "N = min(len(ripe_banana), len(raw_banana))\n",
        "print(f\"Using N = {N} samples per banana class\")\n",
        "\n",
        "# Split into train, val, test\n",
        "def split_data(images, label_name):\n",
        "    train, temp = train_test_split(images, test_size=0.3, random_state=42)\n",
        "    val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
        "    for img in train:\n",
        "        shutil.copy(os.path.join(image_dir, img), f\"{output_dir}/train/{label_name}/{img}\")\n",
        "    for img in val:\n",
        "        shutil.copy(os.path.join(image_dir, img), f\"{output_dir}/val/{label_name}/{img}\")\n",
        "    for img in test:\n",
        "        shutil.copy(os.path.join(image_dir, img), f\"{output_dir}/test/{label_name}/{img}\")\n",
        "\n",
        "split_data(ripe_banana[:N], \"Ripe_Banana\")\n",
        "split_data(raw_banana[:N], \"Raw_Banana\")\n",
        "\n",
        "# Data generators\n",
        "train_gen = ImageDataGenerator(rescale=1./255, rotation_range=20, zoom_range=0.2, horizontal_flip=True)\n",
        "val_test_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data = train_gen.flow_from_directory(f\"{output_dir}/train\", target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "val_data = val_test_gen.flow_from_directory(f\"{output_dir}/val\", target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "test_data = val_test_gen.flow_from_directory(f\"{output_dir}/test\", target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "\n",
        "# Build model\n",
        "base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.compile(optimizer=Adam(1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "model.fit(train_data, validation_data=val_data, epochs=10)\n",
        "\n",
        "# Evaluate\n",
        "loss, accuracy = model.evaluate(test_data)\n",
        "print(f\" Banana Classifier Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Save model\n",
        "model.save('banana_classifier_model.h5')\n",
        "\n",
        "# Convert to TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "with open('banana_classifier_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\" Banana classifier training + test evaluation + TFLite conversion complete.\")\n"
      ],
      "metadata": {
        "id": "WjIl1l2LRsBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=\"banana_classifier_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Get required input shape and dtype\n",
        "input_shape = input_details[0]['shape']        # (1, 224, 224, 3)\n",
        "input_dtype = input_details[0]['dtype']        # float32\n",
        "\n",
        "# Class labels\n",
        "class_labels = [\"Raw_Banana\", \"Ripe_Banana\"]\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Image not found: {image_path}\")\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img_resized = cv2.resize(img_rgb, (224, 224))\n",
        "    img_normalized = img_resized.astype(np.float32) / 255.0\n",
        "    input_tensor = np.expand_dims(img_normalized, axis=0).astype(input_dtype)\n",
        "    return img_rgb, input_tensor\n",
        "\n",
        "def classify_and_show(image_path):\n",
        "    original_img, input_tensor = preprocess_image(image_path)\n",
        "\n",
        "    # Set input tensor\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_tensor)\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Get output tensor\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
        "    pred_idx = np.argmax(output)\n",
        "    confidence = output[pred_idx]\n",
        "    label = f\"{class_labels[pred_idx]} ({confidence * 100:.2f}%)\"\n",
        "\n",
        "    # Draw label on image (red color)\n",
        "    annotated_img = original_img.copy()\n",
        "    cv2.putText(annotated_img, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.7, (255, 0, 0), 2, cv2.LINE_AA)  # Red = (255, 0, 0) in RGB\n",
        "\n",
        "    # Show image in Colab\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(annotated_img)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Prediction\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        " #RUN CLASSIFICATION\n",
        "image_path = \"/content/RIPE_BAN.jpg\"  # Replace with your image\n",
        "classify_and_show(image_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#  Example usage\n",
        "image_paths = [\n",
        "    \"/content/RIPE_BAN.jpg\",\n",
        "    \"/content/RW_BA3.jpg\",\n",
        "    \"/content/RP_BA1.jpg\",\n",
        "    \"/content/RP_BA2.jpg\",\n",
        "    \"/content/RW_BA1.jpg\"\n",
        "]\n",
        "\n",
        "for image_path in image_paths:\n",
        "    classify_and_show(image_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "2pnaFA0LSeup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Raspberry pi code\n",
        "# Fruit Ripeness Classifier for Raspberry Pi using TFLite\n",
        "# 1. Captures image using libcamera-still\n",
        "# 2. Classifies with mango model\n",
        "# 3. If Not_a_Mango or low confidence â†’ uses banana model\n",
        "# 4. Shows prediction on image + waits for manual close\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tflite_runtime.interpreter as tflite\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "# --- TFLite model paths ---\n",
        "MANGO_MODEL_PATH = \"mango_classifier_model.tflite\"\n",
        "BANANA_MODEL_PATH = \"banana_classifier_model.tflite\"\n",
        "\n",
        "# --- Class names ---\n",
        "MANGO_CLASSES = [\"Raw_Mango\", \"Ripe_Mango\", \"Not_a_Mango\"]\n",
        "BANANA_CLASSES = [\"Raw_Banana\", \"Ripe_Banana\"]\n",
        "\n",
        "# --- Load models ---\n",
        "def load_interpreter(model_path):\n",
        "    interpreter = tflite.Interpreter(model_path=model_path)\n",
        "    interpreter.allocate_tensors()\n",
        "    return interpreter\n",
        "\n",
        "mango_interpreter = load_interpreter(MANGO_MODEL_PATH)\n",
        "banana_interpreter = load_interpreter(BANANA_MODEL_PATH)\n",
        "\n",
        "# --- Preprocess image ---\n",
        "def preprocess(frame):\n",
        "    img = cv2.resize(frame, (224, 224))\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "    return np.expand_dims(img, axis=0)\n",
        "\n",
        "# --- Prediction function ---\n",
        "def predict(interpreter, input_tensor, class_names):\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_tensor)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
        "    class_idx = np.argmax(output)\n",
        "    confidence = float(output[class_idx])\n",
        "    return class_names[class_idx], confidence\n",
        "\n",
        "# --- Capture using libcamera ---\n",
        "def capture_image():\n",
        "    path = \"/home/pi/captured.jpg\"\n",
        "    print(\" Capturing image...\")\n",
        "    subprocess.run([\n",
        "        \"libcamera-still\", \"-o\", path, \"-t\", \"1000\",\n",
        "        \"--width\", \"640\", \"--height\", \"480\", \"--nopreview\"\n",
        "    ], check=True)\n",
        "\n",
        "    if not os.path.exists(path):\n",
        "        raise RuntimeError(\"Image capture failed.\")\n",
        "    image = cv2.imread(path)\n",
        "    if image is None:\n",
        "        raise RuntimeError(\" Could not read image.\")\n",
        "    return image\n",
        "\n",
        "# --- Main classifier logic ---\n",
        "def run_classifier():\n",
        "    frame = capture_image()\n",
        "    input_tensor = preprocess(frame)\n",
        "\n",
        "    # Step 1: Mango model\n",
        "    mango_label, mango_conf = predict(mango_interpreter, input_tensor, MANGO_CLASSES)\n",
        "    print(f\" Mango Model: {mango_label} ({mango_conf:.2f})\")\n",
        "\n",
        "    if mango_label == \"Not_a_Mango\" or mango_conf < 0.85:\n",
        "        banana_label, banana_conf = predict(banana_interpreter, input_tensor, BANANA_CLASSES)\n",
        "        label = banana_label\n",
        "        confidence = banana_conf\n",
        "        print(f\"Banana Model: {label} ({confidence:.2f})\")\n",
        "    else:\n",
        "        label = mango_label\n",
        "        confidence = mango_conf\n",
        "\n",
        "    #  Display result\n",
        "    cv2.putText(frame, f\"{label} ({confidence:.2f})\", (10, 35),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "    print(f\" Final Prediction: {label} ({confidence:.2f})\")\n",
        "    cv2.imshow(\"Fruit Classifier\", frame)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# --- Run program ---\n",
        "if name == \"main\":\n",
        "    run_classifier()"
      ],
      "metadata": {
        "id": "fnBldrqoTJVr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}